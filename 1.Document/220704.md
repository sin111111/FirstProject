# 1. 코드리뷰
## 코드 A
  ```
  soup = BeautifulSoup(html.content, 'html.parser')
  html.close()

  tbody = soup.find('tbody')
  data = {}
  df = pd.DataFrame(data, columns=['순위','팀','경기수','세트수','공격','블로킹','서브','득점'])

  for i in range(1,8):
      row = tbody.select_one('tr:nth-child('+str(i)+')')
      temp_array = []
      for ii in range(1,9):
          temp_array.append(row.select_one('td:nth-child('+str(ii)+')').get_text())
      df.loc[i-1] = temp_array
  ```
## 코드 B
  ```
  soup = BeautifulSoup(html.content, 'html.parser')
  html.close()

  col_list = [] # 테이블 columns
  col_data = soup.findAll("th", scope="col")

  for item in col_data:
      col_list.append(item.text) # 컬럼명 # ['순위', '팀', '경기수', '세트수', '공격', '블로킹', '서브', '득점']

  row_data = soup.select("table > tbody > tr > td") # table rows

  dataset = []

  for idx, item in enumerate(row_data):
      num = idx/8
      row_idx = idx//8
      if(num == row_idx):
          dataset.append([])

      dataset[row_idx].append(item.text)

  df = pd.DataFrame(dataset, columns=col_list)
  ```
  
  ***
## 장단점 비교
  1. B에 비해 A는 data를 구하는 방식이 보다 간결하다.  
    * B는 select를 이용하여 모든 data를 구한 후, for문을 통해 다시금 그 data를 __2차 가공__ 하는 방식을 사용했다.  
    * A는 __이중 for문__ 을 통해 원하는 data만을 select_one 메소드를 이용하여 구하는 방식을 사용했다.
        * 첫번째 for문: idx 별 row 전체를 구한다.
        * 두번째 for문: idx 별 row의 해당 column idx 별 data를 구한다.  
 
    
    
  2. B에 비해 A가 HTML 특성을 효율적으로 이용했다.  
    * A는 row data가 컬럼 index 별로 존재함을 알고 __:nth-child()__ CSS 속성을 사용했다.  
    * A는 row data가 tbody 태그 내에 존재함을 알고 data를 찾는 범위를 좁혔다.

      ```
      tbody = soup.find('tbody')
      ```
    
  3. B는 column list와 for문 range를 직접 구했다.  




# 2. 함수 선언 및 사용, url request 요청 시 파라미터 전달 예제
## 데이터 가공 형식을 함수형태로 만들기
  * 1의 코드 2개 중 코드 A를 사용한다.
  ```
  # 빈 데이터프레임에 데이터 넣기
  def insert_data(df, tbody, row_num, columns_count):
      for i in range(1, row_num+1):
          row = tbody.select_one('tr:nth-child('+str(i)+')')
          temp_array = []
          for j in range(1, columns_count+1):
              temp_array.append(row.select_one('td:nth-child('+str(j)+')').get_text())
          df.loc[i-1] = temp_array

      return df
 ```
 * 함수의 매개변수 설명
    * `df`: 빈 데이터({})와 컬럼정보만을 사용한 빈 데이터프레임
    * `tbody`: row_data를 구할 수 있는 tbody
    * `row_num`: 해당 row_data의 최대 index
    * `columns_count`: column 개수. 리스트의 경우 len(columns_list)
* 아래와 같이 사용할 수 있다.
    ```
    df = insert_data(data_frame, tbody, 7, 8)
    ```
    
## request 요청 시 파라미터 전달하기
  * request 요청 중 get 메소드를 사용한다.
  * KOVO 연맹 사이트의 팀 누적 기록은 '득점', '공격' 등 다양한 부문의 기록을 볼 수 있으며, 이는 __'part'__ 라는 변수명의 값으로 전달된다.
      ![image](https://user-images.githubusercontent.com/106735612/177340853-710c2b13-b6cf-4735-8198-26e1a2340335.png)  
      물론 이 외에도 다양한 변수들을 전달하지만, 이 예제에서는 'part' 변수에만 집중한다.
  * 변수의 key값과 value값은 HTML을 보면 확인할 수 있다.
      ![image](https://user-images.githubusercontent.com/106735612/177341649-9df0934c-4c85-472e-94c8-70c6dc9297b4.png)
  * select 태그의 key값과 value값을 지닌 __dict__ 객체를 만드는 함수를 선언한다.
      ```
      # 파라미터 지정
      def request_param(paramtype):
        key = 'part'
        param_dict = {
          '득점' : 'point',
          '공격' : 'at',
          '오픈공격' : 'oa',
          '시간차공격' : 'ta',
          '이동공격' : 'mad',
          '후위공격' : 'ba',
          '속공' : 'sa',
          '퀵오픈' : 'csa',
          '서브' : 's',
          '블로킹' : 'b',
          '디그' : 'd',
          '세트' : 'set',
          '리시브' : 'r',
          '벌칙' : 'w',
          '범실' : 'e',
          '팀범실' : 'te'
        }

      return { key : param_dict[paramtype] }      
      ```
  * 아래와 같이 get 메소드 이용시 data의 매개변수값에 지정하여 request를 요청한다.
      ```
      url = 'https://www.kovo.co.kr/stats/42001_team-totalrecord.asp'
      
      dataparam = request_param('팀범실')
      html = requests.get(url, verify=False, data=dataparam)
      
      if(html.status_code == 200):
        soup = BeautifulSoup(html.content, 'html.parser')
        html.close()
      ```
    아래의 `팀범실`에 관한 data를 확인할 수 있다.  
    ![image](https://user-images.githubusercontent.com/106735612/177342678-fafee932-8f5d-458b-8c61-2e21c35571ca.png)
  ***
## 전체 코드
  ```
  # %%
  from bs4 import BeautifulSoup
  import requests
  import pandas as pd

  # 파라미터 지정
  def request_param(paramtype):
      key = 'part'
      param_dict = {
          '득점' : 'point',
          '공격' : 'at',
          '오픈공격' : 'oa',
          '시간차공격' : 'ta',
          '이동공격' : 'mad',
          '후위공격' : 'ba',
          '속공' : 'sa',
          '퀵오픈' : 'csa',
          '서브' : 's',
          '블로킹' : 'b',
          '디그' : 'd',
          '세트' : 'set',
          '리시브' : 'r',
          '벌칙' : 'w',
          '범실' : 'e',
          '팀범실' : 'te'
      }

      return { key : param_dict[paramtype] }


  # 컬럼 정보 추출
  def set_columns(soup):
      col_list = [] # 테이블 columns
      col_data = soup.findAll('th', scope='col')

      for item in col_data:
          col_list.append(item.text) # 컬럼명 # ['순위', '팀', '경기수', '세트수', '공격', '블로킹', '서브', '득점']

      return col_list



  # 빈 데이터프레임 생성
  def create_dataframe(col_list):
      null_data = {}
      data_frame = pd.DataFrame(null_data, columns=col_list)

      return data_frame


  # tbody
  def get_tbody(soup):
      tbody = soup.find('tbody')
      return tbody


  # row num
  def get_rownum(tbody):
      row_num = len(tbody.select('tr'))

      return row_num


  # column count
  def get_colmuns_count(col_list):
      columns_count = len(col_list)

      return columns_count


  # 빈 데이터프레임에 데이터 넣기
  def insert_data(df, tbody, row_num, columns_count):
      for i in range(1, row_num+1):
          row = tbody.select_one('tr:nth-child('+str(i)+')')
          temp_array = []
          for j in range(1, columns_count+1):
              temp_array.append(row.select_one('td:nth-child('+str(j)+')').get_text())
          df.loc[i-1] = temp_array

      return df


  def preprocess_data():
      col_list = set_columns(soup)
      data_frame = create_dataframe(col_list)
      tbody = get_tbody(soup)
      row_num  = get_rownum(tbody)
      columns_count = get_colmuns_count(col_list)

      df = insert_data(data_frame, tbody, row_num, columns_count)
      return df



  # %%
  url = 'https://www.kovo.co.kr/stats/42001_team-totalrecord.asp'

  dataparam = request_param('팀범실')
  html = requests.get(url, verify=False, data=dataparam)

  # %%
  if(html.status_code == 200):
      soup = BeautifulSoup(html.content, 'html.parser')
      html.close()


  # %%
  df = preprocess_data()
  df
  ```

    
    
